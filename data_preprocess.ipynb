{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import jieba.analyse\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据并预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['弹幕', '类别'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>弹幕</th>\n",
       "      <th>类别</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>你代言都和他接同一家？？？？</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>《我   很   内   向》</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>不管是不是笋 秀芬看到即爽到</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>你好爱他</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>西蒙他老婆的战歌</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1190</th>\n",
       "      <td>啊啊啊鹿晗</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>啊啊啊啊啊啊啊啊，鹿鹿子</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>就尼玛离谱，鹿晗怎么能这么好看</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>完颜团不是吹的</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>啊啊啊啊啊啊伯贤也太嫩了！！！！可爱死啦！！！</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>48908 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           弹幕  类别\n",
       "0              你代言都和他接同一家？？？？   2\n",
       "1             《我   很   内   向》   1\n",
       "2              不管是不是笋 秀芬看到即爽到   0\n",
       "3                        你好爱他   0\n",
       "5                    西蒙他老婆的战歌   0\n",
       "...                       ...  ..\n",
       "1190                    啊啊啊鹿晗   0\n",
       "1192             啊啊啊啊啊啊啊啊，鹿鹿子   3\n",
       "1194          就尼玛离谱，鹿晗怎么能这么好看   3\n",
       "1195                  完颜团不是吹的   2\n",
       "1196  啊啊啊啊啊啊伯贤也太嫩了！！！！可爱死啦！！！   0\n",
       "\n",
       "[48908 rows x 2 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use glob to get all the csv files \n",
    "# in the folder\n",
    "path = r\"./data/source_data/\"\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "df_all = pd.DataFrame({\"弹幕\":[],\"类别\":[]})\n",
    "print(df_all.columns)\n",
    "df = 0\n",
    "for f in csv_files:\n",
    "    df = pd.read_csv(f) \n",
    "    df = df.iloc[:,-2:]\n",
    "    df.columns = [\"弹幕\", \"类别\"]   \n",
    "    df_all = pd.concat([df_all, df],axis=0)\n",
    "    # print(df_all[\"弹幕\"][0])  \n",
    "\n",
    "df_all.dropna(inplace=True) \n",
    "df_all[\"类别\"] = df_all[\"类别\"].apply(lambda x: int(x))\n",
    "df_all.drop_duplicates(subset=[\"弹幕\",\"类别\"],keep='first',inplace=True)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['弹幕', '类别'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>弹幕</th>\n",
       "      <th>类别</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>----------------</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>有个东西</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-----------------</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>。           。</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>做飞机过来的哈哈哈哈哈哈哈哈哈哈哈哈哈哈</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3952</th>\n",
       "      <td>做好心理准备</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953</th>\n",
       "      <td>做好准备，前方巨高能</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3954</th>\n",
       "      <td>做死小能手</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955</th>\n",
       "      <td>做这么让你看剧情?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>31352 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                弹幕  类别\n",
       "0                                ?   4\n",
       "1                 ----------------   4\n",
       "2                             有个东西   4\n",
       "3                -----------------   4\n",
       "4            。           。           4\n",
       "...                            ...  ..\n",
       "3951          做飞机过来的哈哈哈哈哈哈哈哈哈哈哈哈哈哈   0\n",
       "3952                        做好心理准备   4\n",
       "3953                    做好准备，前方巨高能   4\n",
       "3954                         做死小能手   4\n",
       "3955                     做这么让你看剧情?   4\n",
       "\n",
       "[31352 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r\"./data-extra\"\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "df_all_extra = pd.DataFrame({\"弹幕\":[],\"类别\":[]})\n",
    "print(df_all_extra.columns)\n",
    "df = 0\n",
    "for f in csv_files:\n",
    "    df = pd.read_csv(f) \n",
    "    df = df.iloc[:,:2]\n",
    "    df.columns = [\"弹幕\", \"类别\"]   \n",
    "    df_all_extra = pd.concat([df_all_extra, df],axis=0)\n",
    "df_all_extra.dropna(inplace=True) \n",
    "df_all_extra[\"类别\"] = df_all_extra[\"类别\"].apply(lambda x: int(x))\n",
    "df_all_extra.drop_duplicates(subset=[\"弹幕\",\"类别\"],keep='first',inplace=True)\n",
    "df_all_extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>弹幕</th>\n",
       "      <th>类别</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>你代言都和他接同一家？？？？</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>《我   很   内   向》</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>不管是不是笋 秀芬看到即爽到</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>你好爱他</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>西蒙他老婆的战歌</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3951</th>\n",
       "      <td>做飞机过来的哈哈哈哈哈哈哈哈哈哈哈哈哈哈</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3952</th>\n",
       "      <td>做好心理准备</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3953</th>\n",
       "      <td>做好准备，前方巨高能</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3954</th>\n",
       "      <td>做死小能手</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3955</th>\n",
       "      <td>做这么让你看剧情?</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>80260 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                        弹幕  类别\n",
       "0           你代言都和他接同一家？？？？   2\n",
       "1          《我   很   内   向》   1\n",
       "2           不管是不是笋 秀芬看到即爽到   0\n",
       "3                     你好爱他   0\n",
       "5                 西蒙他老婆的战歌   0\n",
       "...                    ...  ..\n",
       "3951  做飞机过来的哈哈哈哈哈哈哈哈哈哈哈哈哈哈   0\n",
       "3952                做好心理准备   4\n",
       "3953            做好准备，前方巨高能   4\n",
       "3954                 做死小能手   4\n",
       "3955             做这么让你看剧情?   4\n",
       "\n",
       "[80260 rows x 2 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all = pd.concat([df_all, df_all_extra],axis=0)\n",
    "df_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# labels = [\"高兴\",\"难过\",\"愤怒\",\"惊讶\",\"负样本\"]\n",
    "# for i in range(len(labels)):\n",
    "#     df_all[\"类别\"][df_all[\"类别\"]==i] = labels[i]\n",
    "# df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache C:\\Users\\Sion\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 0.590 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    加载本地字典：\n",
    "    【1】自定义字典\n",
    "    【2】停用词字典\n",
    "\"\"\"\n",
    "local_dic_name = './data/userdict.txt'\n",
    "local_stopwords_name = './data/stopwords_dic.txt'\n",
    "jieba.load_userdict(local_dic_name)\n",
    "jieba.load_userdict(local_stopwords_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_x = []\n",
    "dataset_y = []\n",
    "for i in range(len(df_all)):\n",
    "    str_t = str(df_all.iloc[i][\"弹幕\"])\n",
    "    label = int(df_all.iloc[i][\"类别\"])\n",
    "    word_list = jieba.lcut(str_t)\n",
    "    dataset_x.append(word_list)\n",
    "    dataset_y.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['你', '代言', '都', '和', '他', '接同', '一家', '？', '？', '？', '？'],\n",
       "  ['《', '我', ' ', ' ', ' ', '很', ' ', ' ', ' ', '内', ' ', ' ', ' ', '向', '》'],\n",
       "  ['不管', '是不是', '笋', ' ', '秀芬', '看到', '即爽', '到'],\n",
       "  ['你好', '爱', '他'],\n",
       "  ['西蒙', '他', '老婆', '的', '战歌']],\n",
       " [2, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_x[:5],dataset_y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 去除停用词(暂时不使用)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\"\n",
    "#     函数功能：创建停用词list\n",
    "#     参数：\n",
    "#         filepath：停用词典地址\n",
    "#     返回：\n",
    "#          停用词list\n",
    "# \"\"\"\n",
    "# def stopwordslist(local_stopwords_name):\n",
    "#     stopwords = [line.strip() for line in open(local_stopwords_name, 'r', encoding='utf-8').readlines()]\n",
    "#     return stopwords\n",
    "\n",
    "# stopwords = stopwordslist(local_stopwords_name)\n",
    "\n",
    "# def word_filter(result):\n",
    "#     stopwords = stopwordslist(local_stopwords_name)\n",
    "#     body = ''\n",
    "#     for w in result:\n",
    "#         if w.flag != 'x' and w.flag != 'r' and w.flag != 'ul' \\\n",
    "#                 and w.flag != 'uj' and w.flag != 'y' and w.flag != 'q'\\\n",
    "#                 and w.flag != 'd' and w.flag != 'm' and w.flag != 'eng':\n",
    "#             if w.word not in stopwords:\n",
    "#                 body += w.word + '\\n'\n",
    "#     # 提取关键词\n",
    "#     tag = jieba.analyse.extract_tags(body, 5)\n",
    "#     # print(tag)\n",
    "#     # 生成关键词比重词典\n",
    "#     # key = jieba.analyse.textrank(body, topK=100, withWeight=True)\n",
    "#     # keywords = dict()\n",
    "#     # for i in key:\n",
    "#     #    keywords[i[0]] = i[1]\n",
    "#     # print(keywords)\n",
    "#     return body\n",
    "\n",
    "\n",
    "# for i in range(len(dataset)):\n",
    "#     dataset[i][0] = word_filter(dataset[i][0])\n",
    "\n",
    "# dataset[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 根据词频OneHot编码（暂时不用）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 将原始训练和测试文本转化为特征向量\n",
    "# from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "# # count_vec=CountVectorizer() #创建词袋数据结构\n",
    "# count_vec=TfidfVectorizer() #根据词频-逆文档频率\n",
    "# dataset_count_x = count_vec.fit_transform(dataset_x) \n",
    "# dataset_count_x= dataset_count_x.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "# 训练word to vector 的 word embedding\n",
    "model = Word2Vec(dataset_x,     # 上文处理过的全部语料\n",
    "                 min_count=1,  # 词频阈值 词出现的频率 小于这个频率的词 将不予保存\n",
    "                 workers=12, # worker是线程数\n",
    "                 window=5  # 窗口大小 表示当前词与预测词在一个句子中的最大距离是多少\n",
    "                 )\n",
    "model.save('./models/Word2vec_v1')  # 保存模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "model = gensim.models.Word2Vec.load(\"./models/Word2vec_v1\")#加载"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 获取词向量\n",
    "model.wv.get_vector(\"狂喜\").shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_vector_x = []\n",
    "for sentence in dataset_x:\n",
    "    vector_x = []\n",
    "    for word in sentence:\n",
    "        vector_x.append(model.wv.get_vector(word))\n",
    "    dataset_vector_x.append(vector_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11, 15)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_vector_x[0]),len(dataset_vector_x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 标签OneHot编码"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(80260, 5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder()\n",
    "dataset_y = np.array(dataset_y).reshape(-1,1)\n",
    "enc.fit(dataset_y)\n",
    "dataset_onehot_y = enc.transform(dataset_y).toarray()\n",
    "dataset_onehot_y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 保存数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(dataset_vector_x,\"dataset/dataset_x\")\n",
    "torch.save(dataset_onehot_y,\"dataset/dataset_y\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6429919fe5eee10fa3db4376c75d0431aac4ee64633f3fde6de3e71a7b7c5c41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
