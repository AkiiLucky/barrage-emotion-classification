{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 数据预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import jieba\n",
    "import jieba.posseg as pseg\n",
    "import jieba.analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 读取数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['弹幕', '类别'], dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>弹幕</th>\n",
       "      <th>类别</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>你代言都和他接同一家？？？？</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>《我   很   内   向》</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>不管是不是笋 秀芬看到即爽到</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>你好爱他</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>你好爱他</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>啊啊啊啊啊啊啊啊，鹿鹿子</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1193</th>\n",
       "      <td>好丝滑</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194</th>\n",
       "      <td>就尼玛离谱，鹿晗怎么能这么好看</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1195</th>\n",
       "      <td>完颜团不是吹的</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1196</th>\n",
       "      <td>啊啊啊啊啊啊伯贤也太嫩了！！！！可爱死啦！！！</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70950 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                           弹幕  类别\n",
       "0              你代言都和他接同一家？？？？   2\n",
       "1             《我   很   内   向》   1\n",
       "2              不管是不是笋 秀芬看到即爽到   0\n",
       "3                        你好爱他   0\n",
       "4                        你好爱他   0\n",
       "...                       ...  ..\n",
       "1192             啊啊啊啊啊啊啊啊，鹿鹿子   3\n",
       "1193                      好丝滑   0\n",
       "1194          就尼玛离谱，鹿晗怎么能这么好看   3\n",
       "1195                  完颜团不是吹的   2\n",
       "1196  啊啊啊啊啊啊伯贤也太嫩了！！！！可爱死啦！！！   0\n",
       "\n",
       "[70950 rows x 2 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# use glob to get all the csv files \n",
    "# in the folder\n",
    "path = r\"./data/source_data/\"\n",
    "csv_files = glob.glob(os.path.join(path, \"*.csv\"))\n",
    "df_all = pd.DataFrame({\"弹幕\":[],\"类别\":[]})\n",
    "print(df_all.columns)\n",
    "df = 0\n",
    "for f in csv_files:\n",
    "    df = pd.read_csv(f) \n",
    "    df = df.iloc[:,-2:]\n",
    "    df.columns = [\"弹幕\", \"类别\"]   \n",
    "    df_all = pd.concat([df_all, df],axis=0)\n",
    "    # print(df_all[\"弹幕\"][0])  \n",
    "\n",
    "df_all.dropna(inplace=True) \n",
    "df_all[\"类别\"] = df_all[\"类别\"].apply(lambda x: int(x))\n",
    "df_all"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分词"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 待分词文件列表\n",
    "file_list = []\n",
    "\n",
    "\"\"\"\n",
    "    加载本地字典：\n",
    "    【1】自定义字典\n",
    "    【2】停用词字典\n",
    "\"\"\"\n",
    "local_dic_name = './data/userdict.txt'\n",
    "local_stopwords_name = './data/stopwords_dic.txt'\n",
    "jieba.load_userdict(local_dic_name)\n",
    "jieba.load_userdict(local_stopwords_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    函数功能：创建停用词list\n",
    "    参数：\n",
    "        filepath：停用词典地址\n",
    "    返回：\n",
    "         停用词list\n",
    "\"\"\"\n",
    "def stopwordslist(local_stopwords_name):\n",
    "    stopwords = [line.strip() for line in open(local_stopwords_name, 'r', encoding='utf-8').readlines()]\n",
    "    return stopwords\n",
    "\n",
    "stopwords = stopwordslist(local_stopwords_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "西蒙 nr\n",
      "他 r\n",
      "老婆 n\n",
      "的 uj\n",
      "战歌 n\n"
     ]
    }
   ],
   "source": [
    "str1 = df_all.iloc[5][\"弹幕\"]\n",
    "str1_list = pseg.cut(str1)\n",
    "for word, flag in str1_list:\n",
    "    print('%s %s' % (word, flag)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 停用词过滤(未完成)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "    函数功能：对词语进行过滤、降噪处理\n",
    "    参数：\n",
    "        result：未过滤的分词结果\n",
    "    返回：\n",
    "         body：过滤的分词结果（字符串）\n",
    "\"\"\"\n",
    "# def word_filter(result):\n",
    "#     stopwords = stopwordslist(local_stopwords_name)\n",
    "#     body = ''\n",
    "#     for w in result:\n",
    "#         if w.flag != 'x' and w.flag != 'r' and w.flag != 'ul' \\\n",
    "#                 and w.flag != 'uj' and w.flag != 'y' and w.flag != 'q'\\\n",
    "#                 and w.flag != 'd' and w.flag != 'm' and w.flag != 'eng':\n",
    "#             if w.word not in stopwords:\n",
    "#                 body += w.word + '\\n'\n",
    "#     # 提取关键词\n",
    "#     tag = jieba.analyse.extract_tags(body, 5)\n",
    "#     print(tag)\n",
    "#     # 生成关键词比重词典\n",
    "#     # key = jieba.analyse.textrank(body, topK=100, withWeight=True)\n",
    "#     # keywords = dict()\n",
    "#     # for i in key:\n",
    "#     #    keywords[i[0]] = i[1]\n",
    "#     # print(keywords)\n",
    "#     return body\n",
    "\n",
    "# word_filter(str1_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "6429919fe5eee10fa3db4376c75d0431aac4ee64633f3fde6de3e71a7b7c5c41"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
